{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laxpIwedmpfn"
      },
      "outputs": [],
      "source": [
        "# KCB AI & Data Science\n",
        "\n",
        "# Predicting Diabetes Risk Using Patient Health Indicators and AI Models\n",
        "\n",
        "# Submitted By\n",
        "# Name: GILBERT WALIUBA\n",
        "# Email: gilbert@haofinder.com\n",
        "# Phone: +254 715 560 734\n",
        "\n",
        "#  Institution\n",
        "# ADNIAN LABS\n",
        "\n",
        "# Date of Submission\n",
        "# 15th SEPT 2025\n",
        "\n",
        "# Dataset Source: Pima Indians Diabetes Database\n",
        "\n",
        "\"\"\"\n",
        "Project structure\n",
        "- Data loading\n",
        "- Data inspection\n",
        "- Preprocessing (missing values, scaling)\n",
        "- Exploratory Data Analysis (plots)\n",
        "- Feature engineering\n",
        "- Model training (Logistic Regression, Decision Tree, Random Forest, SVM, MLP)\n",
        "- Evaluation (confusion matrix, classification report, ROC-AUC)\n",
        "- Hyperparameter tuning (GridSearchCV)\n",
        "- Cross-validation\n",
        "- Feature importance and model saving\n",
        "- Generate a short markdown report file\n",
        "\n",
        "Notes for Google Colab:\n",
        "- Run each cell sequentially. If running as a script, plotting windows will appear inline in Jupyter.\n",
        "- This script uses common libraries: pandas, numpy, matplotlib, seaborn, scikit-learn, joblib.\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------\n",
        "# 0. Imports and settings\n",
        "# ---------------------------\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,\n",
        "                             RocCurveDisplay, PrecisionRecallDisplay, accuracy_score)\n",
        "import joblib\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Create output directory\n",
        "OUT_DIR = Path('diabetes_capstone_outputs')\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Load dataset\n",
        "# ---------------------------\n",
        "# Using the common Pima Indians dataset CSV hosted at a stable URL\n",
        "URL = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\n",
        "           \"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\",\"Outcome\"]\n",
        "\n",
        "print('Loading dataset...')\n",
        "df = pd.read_csv(URL, names=columns)\n",
        "print('Loaded:', df.shape)\n",
        "\n",
        "# Quick peek\n",
        "print(df.head())\n",
        "\n",
        "# Save a copy\n",
        "df.to_csv(OUT_DIR / 'raw_pima_diabetes.csv', index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Initial inspection\n",
        "# ---------------------------\n",
        "print('\\nData info:')\n",
        "print(df.info())\n",
        "print('\\nStatistics:')\n",
        "print(df.describe().T)\n",
        "\n",
        "# Check target balance\n",
        "print('\\nOutcome distribution:')\n",
        "print(df['Outcome'].value_counts())\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Data cleaning & preprocessing\n",
        "# ---------------------------\n",
        "# Replace biologically-impossible zeroes with NaN for specific columns\n",
        "cols_with_zero = [\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\"]\n",
        "df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)\n",
        "\n",
        "print('\\nMissing value counts after replacing zeroes:')\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Impute missing values with median (robust for skewed data)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df[cols_with_zero] = imputer.fit_transform(df[cols_with_zero])\n",
        "\n",
        "print('\\nMissing value counts after imputation:')\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Sanity: check distributions after imputation\n",
        "print('\\nPost-imputation descriptive stats:')\n",
        "print(df[cols_with_zero].describe().T)\n",
        "\n",
        "# Feature matrix and target\n",
        "X = df.drop('Outcome', axis=1).copy()\n",
        "y = df['Outcome'].copy()\n",
        "\n",
        "# Scale numeric features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Save preprocessed data\n",
        "pd.concat([X_scaled, y.reset_index(drop=True)], axis=1).to_csv(OUT_DIR / 'preprocessed_pima_diabetes.csv', index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Exploratory Data Analysis (EDA)\n",
        "# ---------------------------\n",
        "# Target distribution plot\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=y)\n",
        "plt.title('Outcome Distribution (0: No Diabetes, 1: Diabetes)')\n",
        "plt.savefig(OUT_DIR / 'outcome_distribution.png')\n",
        "plt.close()\n",
        "\n",
        "# Histograms for features\n",
        "X.hist(bins=20, figsize=(12,10))\n",
        "plt.suptitle('Feature Distributions (raw scale)')\n",
        "plt.savefig(OUT_DIR / 'feature_histograms.png')\n",
        "plt.close()\n",
        "\n",
        "# Correlation heatmap (on raw X)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(pd.concat([X, y], axis=1).corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.savefig(OUT_DIR / 'correlation_heatmap.png')\n",
        "plt.close()\n",
        "\n",
        "# Boxplots to show potential outliers\n",
        "plt.figure(figsize=(12,8))\n",
        "X.boxplot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Boxplots of features')\n",
        "plt.savefig(OUT_DIR / 'boxplots_features.png')\n",
        "plt.close()\n",
        "\n",
        "# Pairplot on a sample (to keep it fast)\n",
        "sample = pd.concat([X.sample(250, random_state=42), y.sample(250, random_state=42).reset_index(drop=True)], axis=1)\n",
        "# pairplot can be slow; we save only if seaborn supports it quickly\n",
        "try:\n",
        "    sns.pairplot(sample, hue='Outcome', corner=True)\n",
        "    plt.savefig(OUT_DIR / 'pairplot_sample.png')\n",
        "    plt.close()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Feature engineering\n",
        "# ---------------------------\n",
        "# Example features: Age group, BMI x Age interaction\n",
        "X_fe = X.copy()\n",
        "# Age group bins\n",
        "age_bins = [20, 30, 40, 50, 60, 100]\n",
        "age_labels = ['20-29','30-39','40-49','50-59','60+']\n",
        "X_fe['AgeGroup'] = pd.cut(X_fe['Age'], bins=age_bins, labels=age_labels, right=False)\n",
        "\n",
        "# Interaction term\n",
        "X_fe['BMI_Age'] = X_fe['BMI'] * X_fe['Age']\n",
        "\n",
        "# One-hot encode AgeGroup\n",
        "X_fe = pd.get_dummies(X_fe, columns=['AgeGroup'], drop_first=True)\n",
        "\n",
        "# Scale again after engineering\n",
        "X_fe_scaled = pd.DataFrame(scaler.fit_transform(X_fe), columns=X_fe.columns)\n",
        "\n",
        "# Save engineered features\n",
        "pd.concat([X_fe_scaled, y.reset_index(drop=True)], axis=1).to_csv(OUT_DIR / 'engineered_pima_diabetes.csv', index=False)\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Train-test split\n",
        "# ---------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_fe_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "print('\\nTrain/Test sizes:', X_train.shape, X_test.shape)\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Model definitions and helper functions\n",
        "# ---------------------------\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=2000),\n",
        "    'DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(probability=True, random_state=42),\n",
        "    'MLP': MLPClassifier(max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "\n",
        "def evaluate_model(name, model, Xt, yt, Xv, yv, plot_roc=True):\n",
        "    model.fit(Xt, yt)\n",
        "    preds = model.predict(Xv)\n",
        "    probs = None\n",
        "    try:\n",
        "        probs = model.predict_proba(Xv)[:,1]\n",
        "    except Exception:\n",
        "        try:\n",
        "            probs = model.decision_function(Xv)\n",
        "        except Exception:\n",
        "            probs = None\n",
        "\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    print('Accuracy:', accuracy_score(yv, preds))\n",
        "    print(classification_report(yv, preds))\n",
        "    if probs is not None:\n",
        "        print('ROC-AUC:', roc_auc_score(yv, probs))\n",
        "        # Plot ROC\n",
        "        plt.figure(figsize=(6,5))\n",
        "        RocCurveDisplay.from_estimator(model, Xv, yv)\n",
        "        plt.title(f'ROC Curve - {name}')\n",
        "        plt.savefig(OUT_DIR / f'roc_{name}.png')\n",
        "        plt.close()\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(yv, preds)\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.savefig(OUT_DIR / f'cm_{name}.png')\n",
        "    plt.close()\n",
        "\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Train baseline models\n",
        "# ---------------------------\n",
        "trained_models = {}\n",
        "for name, mdl in models.items():\n",
        "    trained_models[name] = evaluate_model(name, mdl, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 9. Cross-validation scores\n",
        "# ---------------------------\n",
        "print('\\nCross-validation (5-fold) scores:')\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_results = {}\n",
        "for name, mdl in models.items():\n",
        "    scores = cross_val_score(mdl, X_fe_scaled, y, cv=skf, scoring='roc_auc')\n",
        "    cv_results[name] = scores\n",
        "    print(f\"{name}: mean ROC-AUC = {scores.mean():.4f} | std = {scores.std():.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 10. Hyperparameter tuning for top models\n",
        "# ---------------------------\n",
        "# We will tune RandomForest and LogisticRegression as primary candidates\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 6, 10],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs']\n",
        "}\n",
        "\n",
        "print('\\nTuning RandomForest...')\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid_rf = GridSearchCV(rf, param_grid_rf, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
        "grid_rf.fit(X_train, y_train)\n",
        "print('Best RF params:', grid_rf.best_params_)\n",
        "print('Best RF ROC-AUC:', grid_rf.best_score_)\n",
        "\n",
        "print('\\nTuning LogisticRegression...')\n",
        "lr = LogisticRegression(max_iter=2000)\n",
        "grid_lr = GridSearchCV(lr, param_grid_lr, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
        "grid_lr.fit(X_train, y_train)\n",
        "print('Best LR params:', grid_lr.best_params_)\n",
        "print('Best LR ROC-AUC:', grid_lr.best_score_)\n",
        "\n",
        "# Evaluate tuned models on test set\n",
        "best_rf = grid_rf.best_estimator_\n",
        "best_lr = grid_lr.best_estimator_\n",
        "\n",
        "best_rf = evaluate_model('RandomForest_Tuned', best_rf, X_train, y_train, X_test, y_test)\n",
        "best_lr = evaluate_model('LogisticRegression_Tuned', best_lr, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# ---------------------------\n",
        "# 11. Feature importance (Random Forest)\n",
        "# ---------------------------\n",
        "if hasattr(best_rf, 'feature_importances_'):\n",
        "    fi = pd.Series(best_rf.feature_importances_, index=X_fe_scaled.columns).sort_values(ascending=False)\n",
        "    print('\\nTop features by importance:')\n",
        "    print(fi.head(15))\n",
        "    plt.figure(figsize=(8,6))\n",
        "    fi.head(15).plot(kind='bar')\n",
        "    plt.title('Feature Importances - Random Forest')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(OUT_DIR / 'feature_importances_rf.png')\n",
        "    plt.close()\n",
        "\n",
        "# ---------------------------\n",
        "# 12. Save best model and scalers\n",
        "# ---------------------------\n",
        "model_path = OUT_DIR / 'best_model_random_forest.joblib'\n",
        "joblib.dump(best_rf, model_path)\n",
        "scaler_path = OUT_DIR / 'scaler.joblib'\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f'Best model saved to: {model_path}')\n",
        "\n",
        "# ---------------------------\n",
        "# 13. Simple prediction function\n",
        "# ---------------------------\n",
        "\n",
        "def predict_patient(data_dict, model=best_rf, scaler=scaler, feature_columns=X_fe.columns):\n",
        "    # data_dict: dict with keys matching original feature names (Pregnancies, Glucose, ... Age)\n",
        "    df_input = pd.DataFrame([data_dict])\n",
        "    # Impute zeros if present (simple approach)\n",
        "    for c in cols_with_zero:\n",
        "        if c in df_input.columns and df_input.loc[0, c] == 0:\n",
        "            df_input.loc[0, c] = np.nan\n",
        "    df_input[cols_with_zero] = imputer.transform(df_input[cols_with_zero])\n",
        "    # Feature engineering: AgeGroup & BMI_Age\n",
        "    df_input['BMI_Age'] = df_input['BMI'] * df_input['Age']\n",
        "    df_input['AgeGroup'] = pd.cut(df_input['Age'], bins=age_bins, labels=age_labels, right=False)\n",
        "    df_input = pd.get_dummies(df_input, columns=['AgeGroup'], drop_first=True)\n",
        "    # Ensure all expected columns exist\n",
        "    for col in feature_columns:\n",
        "        if col not in df_input.columns:\n",
        "            df_input[col] = 0\n",
        "    df_input = df_input[feature_columns]\n",
        "    # Scale\n",
        "    Xs = scaler.transform(df_input)\n",
        "    pred_prob = model.predict_proba(Xs)[:,1][0]\n",
        "    pred = int(pred_prob >= 0.5)\n",
        "    return {'prediction': pred, 'probability': float(pred_prob)}\n",
        "\n",
        "# Example usage of predict_patient\n",
        "sample_patient = {\n",
        "    'Pregnancies': 2,\n",
        "    'Glucose': 120,\n",
        "    'BloodPressure': 70,\n",
        "    'SkinThickness': 20,\n",
        "    'Insulin': 79,\n",
        "    'BMI': 27.5,\n",
        "    'DiabetesPedigreeFunction': 0.5,\n",
        "    'Age': 29\n",
        "}\n",
        "print('\\nSample prediction:', predict_patient(sample_patient))\n",
        "\n",
        "# ---------------------------\n",
        "# 14. Generate short markdown report\n",
        "# ---------------------------\n",
        "report_md = f\"\"\"\n",
        "# Diabetes Prediction Capstone - Short Report\n",
        "\n",
        "**Dataset:** Pima Indians Diabetes Database (768 records)\n",
        "\n",
        "**Preprocessing:** Zero values in biologically-impossible fields replaced with median. Standard scaling applied. Feature engineering added BMI_Age and AgeGroup bins.\n",
        "\n",
        "**Models trained:** Logistic Regression, Decision Tree, Random Forest, Support Vector Machine, Multi-layer Perceptron.\n",
        "\n",
        "**Best tuned model:** Random Forest (saved in {model_path})\n",
        "\n",
        "**Key performance (test set):**\n",
        "\"\"\"\n",
        "\n",
        "# append test results summary\n",
        "\n",
        "def summarize_metrics(model, X_test, y_test):\n",
        "    preds = model.predict(X_test)\n",
        "    try:\n",
        "        probs = model.predict_proba(X_test)[:,1]\n",
        "        auc = roc_auc_score(y_test, probs)\n",
        "    except Exception:\n",
        "        auc = None\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    rpt = classification_report(y_test, preds, output_dict=True)\n",
        "    return acc, auc, rpt\n",
        "\n",
        "acc_rf, auc_rf, rpt_rf = summarize_metrics(best_rf, X_test, y_test)\n",
        "\n",
        "report_md += f\"- Random Forest accuracy: {acc_rf:.3f}\\n\"\n",
        "if auc_rf is not None:\n",
        "    report_md += f\"- Random Forest ROC-AUC: {auc_rf:.3f}\\n\"\n",
        "\n",
        "report_md += '\\n## Top features (Random Forest)\\n'\n",
        "if 'fi' in locals():\n",
        "    report_md += fi.head(10).to_markdown() + '\\n'\n",
        "\n",
        "report_md += '\\n## Recommendations\\n- Use the model as a screening tool, not a diagnostic tool.\\n- Collect more patient data to improve generalization.\\n- Consider calibration of predicted probabilities before deployment.\\n'\n",
        "\n",
        "with open(OUT_DIR / 'short_report.md', 'w') as f:\n",
        "    f.write(report_md)\n",
        "\n",
        "print('\\nShort report saved to', OUT_DIR / 'short_report.md')\n",
        "\n",
        "# ---------------------------\n",
        "# End of script\n",
        "# ---------------------------\n",
        "print('\\nAll outputs saved to', OUT_DIR)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
